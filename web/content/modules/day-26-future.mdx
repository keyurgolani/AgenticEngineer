---
title: "Day 26: The Future of Agentic AI"
description: "Beyond Text: Vision and On-Device."
week: 4
---

### 26.1 Multi-Modal Agents

Agents that **See**.

- **GPT-4o / Gemini**: Can look at a screenshot and click a button.
- **UI Navigation**: The future of "Browser Agents" that operate SaaS tools directly.

### 26.2 On-Device Agents (Edge AI)

Running Llama-3-8b on a MacBook or iPhone.
The "Personal Privacy Agent" that never sends your data to the cloud.

### 26.3 The Rise of "Vibe Coding"

As coding agents (Cursor, Devin) get better, the role of the engineer shifts.
We are no longer "Typists". We are "Directors".
**Vibe Coding** is the practice of guiding the AI through "Vibes" (High-level intent, aesthetic preference, and behavior description) rather than syntax.

![Vibe Coding Director](/images/vibe_coding.png)
The skill is **Taste**, not **Typing**.
